{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### IMPORT"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "#from community import community_louvain \n",
    "import folium\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MANIPOLAZIONE FILES CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read_csv function which is used to read the required CSV file \n",
    "df = pd.read_csv('./dataset/treni_modificati.csv') \n",
    "\n",
    "\n",
    "\n",
    "# CREAZIONE TRENI_SOLO_CITTA.CSV (ARCHI)\n",
    "# Stampa le colonne presenti nel file CSV\n",
    "print(\"Colonne originali:\", df.columns)\n",
    "\n",
    "# Lista delle colonne da rimuovere\n",
    "colonne_da_tenere = ['stazPart', 'stazArr']\n",
    "\n",
    "# Rimuove le colonne\n",
    "df = df[colonne_da_tenere]\n",
    "\n",
    "# Stampa le colonne rimanenti dopo la rimozione\n",
    "print(\"Colonne dopo la rimozione:\", df.columns)\n",
    "\n",
    "# Salva il DataFrame risultante in un nuovo file CSV\n",
    "df.to_csv('./dataset/treni_solo_citta.csv', index=False)\n",
    "\n",
    "#CREAZIONE CITTA.CSV (NODI)\n",
    "\n",
    "# Unisci le due colonne in una singola serie e ottieni i valori unici\n",
    "df = pd.concat([df['stazPart'], df['stazArr']]).unique()\n",
    "\n",
    "# Converti l'array di città uniche in una lista (opzionale)\n",
    "df = list(df)\n",
    "\n",
    "# Stampa le città uniche\n",
    "print(\"Città uniche:\", df)\n",
    "\n",
    "# Se desideri salvare il risultato in un nuovo file CSV\n",
    "pd.DataFrame(df, columns=['citta_uniche']).to_csv('./dataset/df_citta.csv', index=False)\n",
    "\n",
    "#AGGIUNGE LOCATION\n",
    "# Carica il primo dataset con alcune città italiane\n",
    "df_citta = pd.read_csv('./dataset/df_citta.csv')\n",
    "\n",
    "# Carica il secondo dataset con tutti i comuni italiani e lat/long\n",
    "df_comuni = pd.read_csv('./dataset/comuni_coordinates.csv')\n",
    "\n",
    "# Lista delle colonne da rimuovere\n",
    "colonne_da_tenere = ['DENOMINAZIONE_ITA_ALTRA', 'LAT', 'LON']\n",
    "\n",
    "# Rimuove le colonne\n",
    "df_comuni = df_comuni[colonne_da_tenere]\n",
    "# Salva il DataFrame risultante in un nuovo file CSV\n",
    "df_comuni.to_csv('./dataset/df_comuni.csv', index=False)\n",
    "\n",
    "# Display the first few rows of each dataframe to understand their structure\n",
    "df_comuni.head(), df_citta.head()\n",
    "\n",
    "# Rename the column 'DENOMINAZIONE_ITA_ALTRA' in df_comuni to match 'citta_uniche' in df_citta for merging\n",
    "df_comuni.rename(columns={'DENOMINAZIONE_ITA_ALTRA': 'citta_uniche'}, inplace=True)\n",
    "\n",
    "# Merge the two dataframes on the 'citta_uniche' column\n",
    "merged_data = pd.merge(df_citta, df_comuni, on='citta_uniche', how='inner')\n",
    "\n",
    "# Display the merged dataframe\n",
    "merged_data.head()\n",
    "\n",
    "# Se desideri salvare il risultato in un nuovo file CSV\n",
    "#pd.DataFrame(merged_data).to_csv('./dataset/merged_data.csv', index=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRAFO E MISURAZIONI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LAYOUT DEL GRAFO CHE ABBIAMO DESCRITTO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica il primo CSV con le città uniche e le coordinate\n",
    "df_citta = pd.read_csv('./dataset/lista_citta_con_stazione.csv')\n",
    "\n",
    "# Carica il secondo CSV con le coppie di città di partenza e arrivo\n",
    "df_coppie = pd.read_csv('./dataset/treni_solo_citta.csv')\n",
    "\n",
    "\n",
    "# Creare un grafo non diretto\n",
    "G = nx.Graph()\n",
    "\n",
    "# Mappa per evitare sovrapposizioni di posizioni casuali\n",
    "posizioni_usate = {}\n",
    "\n",
    "# Aggiungi i nodi (città) al grafo con posizioni casuali non sovrapposte\n",
    "for idx, row in df_citta.iterrows():\n",
    "    # Genera posizione casuale non sovrapposta\n",
    "    while True:\n",
    "        x = random.uniform(0, 1)  # Coordinate x casuali tra 0 e 1\n",
    "        y = random.uniform(0, 1)  # Coordinate y casuali tra 0 e 1\n",
    "        pos = (x, y)\n",
    "        if pos not in posizioni_usate.values():\n",
    "            posizioni_usate[row['citta_uniche']] = pos\n",
    "            break\n",
    "    \n",
    "    G.add_node(row['citta_uniche'], pos=pos)\n",
    "\n",
    "# Aggiungi gli archi (connessioni tra città di partenza e arrivo) al grafo\n",
    "for idx, row in df_coppie.iterrows():\n",
    "    G.add_edge(row['stazPart'], row['stazArr'])\n",
    "\n",
    "G.remove_edges_from(nx.selfloop_edges(G))\n",
    "# Disegna il grafo\n",
    "pos = nx.get_node_attributes(G, 'pos')\n",
    "nx.draw(G, pos, with_labels=False, node_color='black', node_size=10, font_size=4, font_color='black', edge_color='grey', width=0.2)\n",
    "\n",
    "# Mostra il grafo\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### MISURAZIONI SUL GRAFO"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calcolo delle misurazioni di centralità e altre metriche\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "betweenness_centrality = nx.betweenness_centrality(G)\n",
    "eigenvector_centrality = nx.eigenvector_centrality(G, max_iter=1000)\n",
    "closeness_centrality = nx.closeness_centrality(G)\n",
    "clustering_coefficient = nx.clustering(G)\n",
    "density = nx.density(G)\n",
    "\n",
    "if nx.is_connected(G):\n",
    "    avg_path_length = nx.average_shortest_path_length(G)\n",
    "    diameter = nx.diameter(G)\n",
    "else:\n",
    "    avg_path_length = None\n",
    "    diameter = None\n",
    "\n",
    "connected_components = list(nx.connected_components(G))\n",
    "connectedness = len(connected_components)\n",
    "\n",
    "core_number = nx.core_number(G)\n",
    "assortativity = nx.degree_assortativity_coefficient(G)\n",
    "bridges = list(nx.bridges(G))\n",
    "\n",
    "# Stampa delle metriche\n",
    "print(\"Degree Centrality:\", degree_centrality)\n",
    "print(\"Betweenness Centrality:\", betweenness_centrality)\n",
    "print(\"Eigenvector Centrality:\", eigenvector_centrality)\n",
    "print(\"Closeness Centrality:\", closeness_centrality)\n",
    "print(\"Clustering Coefficient:\", clustering_coefficient)\n",
    "print(\"Density:\", density)\n",
    "print(\"Number of Connected Components:\", connectedness)\n",
    "print(\"Core Numbers:\", core_number)\n",
    "print(\"Assortativity:\", assortativity)\n",
    "print(\"Bridges:\", bridges)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CENNI TEORICI (PERCHE ABBIAMO SCELTO QUELLE METRICHE) DA SCRIVERE NELLA RELAZIONE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "\n",
    "1. Centralità (Degree, Betweenness, Eigenvector, Closeness)\n",
    "Scopo: Identificare i nodi (comuni) più importanti o influenti nella rete.\n",
    "Misurazioni:\n",
    "Degree Centrality: Indica quanti collegamenti ha un nodo. Può rivelare le stazioni ferroviarie con il maggior numero di connessioni dirette.\n",
    "Betweenness Centrality: Misura il numero di volte che un nodo funge da intermediario nei cammini minimi. Utile per identificare nodi critici che, se rimossi, potrebbero causare disconnessione della rete.\n",
    "Eigenvector Centrality: Valuta l'importanza di un nodo basata sulla centralità dei suoi vicini. Può identificare le stazioni più influenti in un contesto globale.\n",
    "Closeness Centrality: Indica quanto un nodo è \"vicino\" a tutti gli altri nodi. Utile per capire quali stazioni hanno accesso rapido al resto della rete.\n",
    "\n",
    "2. Coefficienti di Clustering e Densità\n",
    "Scopo: Analizzare la coesione e la compattezza della rete.\n",
    "Misurazioni:\n",
    "Clustering Coefficient: Misura la tendenza dei nodi a formare cluster o gruppi. Utile per capire quanto la rete è segmentata in comunità o sub-reti.\n",
    "Density: Rapporto tra il numero di archi presenti e il numero massimo possibile di archi. Indica quanto la rete è densamente connessa.\n",
    "\n",
    "\n",
    "3. Analisi delle Componenti Connesse\n",
    "Scopo: Identificare e analizzare le componenti connesse della rete per capire come la rete potrebbe frammentarsi.\n",
    "Misurazioni:\n",
    "Connected Components: Numero di componenti connesse nella rete. Utile per identificare isole o subnet isolate.\n",
    "\n",
    "4. Core-Periphery Analysis\n",
    "Scopo: Identificare la struttura core-periphery della rete.\n",
    "Misurazioni:\n",
    "Core Number: Utilizzare l'algoritmo di k-core per identificare il nucleo centrale della rete.\n",
    "\n",
    "5. Assortativity\n",
    "Scopo: Valutare se nodi con simili proprietà (ad esempio, grado) tendono a collegarsi tra loro.\n",
    "Misurazioni:\n",
    "Degree Assortativity Coefficient: Misura la correlazione tra i gradi dei nodi connessi. Può indicare se stazioni centrali tendono a collegarsi con altre stazioni centrali.\n",
    "\n",
    "6. Modularity e Community Detection\n",
    "Scopo: Identificare comunità o gruppi di nodi fortemente connessi all'interno della rete.\n",
    "Misurazioni:\n",
    "Modularity: Misura la forza della divisione della rete in moduli o comunità. Utilizzando algoritmi di rilevazione delle comunità come Louvain.\n",
    "\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## MAPPA DELL'ITALIA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Carica il primo CSV con le città uniche e le coordinate\n",
    "df_citta = pd.read_csv('./dataset/merged_data.csv')\n",
    "\n",
    "# Carica il secondo CSV con le coppie di città di partenza e arrivo\n",
    "df_coppie = pd.read_csv('./dataset/treni_solo_citta.csv')\n",
    "\n",
    "\n",
    "# Mappa delle città ai loro set di coordinate\n",
    "citta_coord = {}\n",
    "for idx, row in df_citta.iterrows():\n",
    "    citta_coord[row['citta_uniche']] = (row['LAT'], row['LON'])\n",
    "\n",
    "# Creare una mappa centrata sull'Italia\n",
    "m = folium.Map(location=[41.8719, 12.5674], zoom_start=6, zoom_control=True, scrollWheelZoom=True)\n",
    "geojson_data = './italy.geojson'\n",
    "\n",
    "# Aggiungere i confini delle regioni italiane con bordo nero\n",
    "folium.GeoJson(\n",
    "    geojson_data,\n",
    "    style_function=lambda feature: {\n",
    "        'color': 'black',\n",
    "        'weight': 0.7\n",
    "    }\n",
    ").add_to(m)\n",
    "\n",
    "# Funzione per aggiungere un arco tra le città di partenza e arrivo\n",
    "def aggiungi_arco(mappa, citta_partenza, citta_arrivo):\n",
    "    coord_partenza = citta_coord.get(citta_partenza)\n",
    "    coord_arrivo = citta_coord.get(citta_arrivo)\n",
    "    \n",
    "    if coord_partenza and coord_arrivo:\n",
    "        folium.PolyLine(\n",
    "            locations=[coord_partenza, coord_arrivo],\n",
    "            color='grey',\n",
    "            weight=0.05,\n",
    "            opacity=1  # Imposta l'opacità a 0.5 (50% trasparente)\n",
    "        ).add_to(mappa)\n",
    "\n",
    "# Aggiungi i nodi delle città alla mappa (marcatori rossi)\n",
    "for idx, row in df_citta.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['LAT'], row['LON']],\n",
    "        radius=1,\n",
    "        color='red',\n",
    "        fill=True,\n",
    "        fill_color='red',\n",
    "        fill_opacity=0.7  # Imposta l'opacità a 0.7 (70% trasparente)\n",
    "    ).add_to(m)\n",
    "\n",
    "# Aggiungi gli archi tra le città di partenza e arrivo nel DataFrame delle coppie\n",
    "for idx, row in df_coppie.iterrows():\n",
    "    aggiungi_arco(m, row['stazPart'], row['stazArr'])\n",
    "\n",
    "# Mostrare la mappa\n",
    "m"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# GRAFICI MISURAZIONI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calcola la degree centrality per ogni nodo\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "\n",
    "# Ordina i nodi per degree centrality e prendi i primi 10\n",
    "top_nodes_degree = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "nodes_degree = [node for node, _ in top_nodes_degree]\n",
    "centrality_values_degree = [value for _, value in top_nodes_degree]\n",
    "\n",
    "# Plot a bar chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(nodes_degree, centrality_values_degree, color='skyblue')\n",
    "plt.xlabel('Nodi')\n",
    "plt.ylabel('Degree Centrality')\n",
    "plt.title('Top 10 Degree Centrality dei Nodi')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Calcola la degree centrality per ogni nodo\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "\n",
    "# Ordina i nodi per betweenness centrality e prendi i primi 10\n",
    "top_nodes_betweenness = sorted(betweenness_centrality.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "nodes_betweenness = [node for node, _ in top_nodes_betweenness]\n",
    "centrality_values_betweenness = [value for _, value in top_nodes_betweenness]\n",
    "\n",
    "# Plot a scatter plot\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.scatter(nodes_betweenness, centrality_values_betweenness, color='green', alpha=0.5)\n",
    "plt.xlabel('Nodi')\n",
    "plt.ylabel('Betweenness Centrality')\n",
    "plt.title('Top 10 Betweenness Centrality dei Nodi')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola la degree centrality per ogni nodo\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "\n",
    "# Ordina i nodi per eigenvector centrality e prendi i primi 10\n",
    "top_nodes_eigenvector = sorted(eigenvector_centrality.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "nodes_eigenvector = [node for node, _ in top_nodes_eigenvector]\n",
    "centrality_values_eigenvector = [value for _, value in top_nodes_eigenvector]\n",
    "\n",
    "# Plot a pie chart\n",
    "plt.figure(figsize=(8, 8))\n",
    "plt.pie(centrality_values_eigenvector, labels=nodes_eigenvector, autopct='%1.1f%%', startangle=140)\n",
    "plt.title('Top 10 Eigenvector Centrality dei Nodi')\n",
    "plt.axis('equal')\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola la degree centrality per ogni nodo\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "\n",
    "# Ordina i nodi per closeness centrality e prendi i primi 10\n",
    "top_nodes_closeness = sorted(closeness_centrality.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "nodes_closeness = [node for node, _ in top_nodes_closeness]\n",
    "centrality_values_closeness = [value for _, value in top_nodes_closeness]\n",
    "\n",
    "# Plot a line chart\n",
    "plt.figure(figsize=(10, 6))\n",
    "plt.plot(nodes_closeness, centrality_values_closeness, marker='o', linestyle='-', color='purple')\n",
    "plt.xlabel('Nodi')\n",
    "plt.ylabel('Closeness Centrality')\n",
    "plt.title('Top 10 Closeness Centrality dei Nodi')\n",
    "plt.xticks(rotation=45)\n",
    "plt.grid(True)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# SIMULAZIONE E TESTING"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "File CSV filtrato è stato creato con successo.\n",
      "File CSV filtrato è stato creato con successo.\n"
     ]
    }
   ],
   "source": [
    "# Carica il file CSV\n",
    "df = pd.read_csv('./dataset/treni_solo_citta.csv')\n",
    "\n",
    "# Lista di parole da cercare\n",
    "lista_parole = ['Roma', 'Milano', 'Bologna', 'Torino', 'Napoli']\n",
    "\n",
    "\n",
    "# Filtra il DataFrame rimuovendo le righe che contengono almeno una delle parole dalla lista\n",
    "filtered_df = df[~df['stazPart'].str.contains('|'.join(lista_parole), case=False, na=False)]\n",
    "refiltered_df = filtered_df[~filtered_df['stazArr'].str.contains('|'.join(lista_parole), case=False, na=False)]\n",
    "\n",
    "# Salvataggio del DataFrame filtrato in un nuovo file CSV\n",
    "refiltered_df.to_csv('./dataset/simulazione/treni_solo_citta-.csv', index=False)\n",
    "\n",
    "# Carica il file CSV\n",
    "df = pd.read_csv('./dataset/merged_data.csv')\n",
    "\n",
    "\n",
    "# Filtra il DataFrame rimuovendo le righe che contengono almeno una delle parole dalla lista\n",
    "filtered_df = df[~df['citta_uniche'].str.contains('|'.join(lista_parole), case=False, na=False)]\n",
    "\n",
    "\n",
    "# Salvataggio del DataFrame filtrato in un nuovo file CSV\n",
    "filtered_df.to_csv('./dataset/simulazione/merged_data-.csv', index=False)\n",
    "\n",
    "print(\"File CSV filtrato è stato creato con successo.\")\n",
    "\n",
    "# Carica il file CSV\n",
    "df = pd.read_csv('./dataset/lista_citta_con_stazione.csv')\n",
    "\n",
    "\n",
    "# Filtra il DataFrame rimuovendo le righe che contengono almeno una delle parole dalla lista\n",
    "filtered_df = df[~df['citta_uniche'].str.contains('|'.join(lista_parole), case=False, na=False)]\n",
    "\n",
    "\n",
    "# Salvataggio del DataFrame filtrato in un nuovo file CSV\n",
    "filtered_df.to_csv('./dataset/simulazione/lista_citta_con_stazione-.csv', index=False)\n",
    "\n",
    "print(\"File CSV filtrato è stato creato con successo.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica il primo CSV con le città uniche e le coordinate\n",
    "df_citta = pd.read_csv('./dataset/simulazione/merged_data-.csv')\n",
    "\n",
    "# Carica il secondo CSV con le coppie di città di partenza e arrivo\n",
    "df_coppie = pd.read_csv('./dataset/simulazione/treni_solo_citta-.csv')\n",
    "\n",
    "\n",
    "# Mappa delle città ai loro set di coordinate\n",
    "citta_coord = {}\n",
    "for idx, row in df_citta.iterrows():\n",
    "    citta_coord[row['citta_uniche']] = (row['LAT'], row['LON'])\n",
    "\n",
    "# Creare una mappa centrata sull'Italia\n",
    "m = folium.Map(location=[41.8719, 12.5674], zoom_start=6, zoom_control=True, scrollWheelZoom=True)\n",
    "geojson_data = './italy.geojson'\n",
    "\n",
    "# Aggiungere i confini delle regioni italiane con bordo nero\n",
    "folium.GeoJson(\n",
    "    geojson_data,\n",
    "    style_function=lambda feature: {\n",
    "        'color': 'black',\n",
    "        'weight': 0.7\n",
    "    }\n",
    ").add_to(m)\n",
    "\n",
    "# Funzione per aggiungere un arco tra le città di partenza e arrivo\n",
    "def aggiungi_arco(mappa, citta_partenza, citta_arrivo):\n",
    "    coord_partenza = citta_coord.get(citta_partenza)\n",
    "    coord_arrivo = citta_coord.get(citta_arrivo)\n",
    "    \n",
    "    if coord_partenza and coord_arrivo:\n",
    "        folium.PolyLine(\n",
    "            locations=[coord_partenza, coord_arrivo],\n",
    "            color='grey',\n",
    "            weight=0.05,\n",
    "            opacity=1  # Imposta l'opacità a 0.5 (50% trasparente)\n",
    "        ).add_to(mappa)\n",
    "\n",
    "# Aggiungi i nodi delle città alla mappa (marcatori rossi)\n",
    "for idx, row in df_citta.iterrows():\n",
    "    folium.CircleMarker(\n",
    "        location=[row['LAT'], row['LON']],\n",
    "        radius=1,\n",
    "        color='red',\n",
    "        fill=True,\n",
    "        fill_color='red',\n",
    "        fill_opacity=0.7  # Imposta l'opacità a 0.7 (70% trasparente)\n",
    "    ).add_to(m)\n",
    "\n",
    "# Aggiungi gli archi tra le città di partenza e arrivo nel DataFrame delle coppie\n",
    "for idx, row in df_coppie.iterrows():\n",
    "    aggiungi_arco(m, row['stazPart'], row['stazArr'])\n",
    "\n",
    "# Mostrare la mappa\n",
    "m"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Carica il primo CSV con le città uniche e le coordinate\n",
    "df_citta = pd.read_csv('./dataset/simulazione/lista_citta_con_stazione-.csv')\n",
    "\n",
    "# Carica il secondo CSV con le coppie di città di partenza e arrivo\n",
    "df_coppie = pd.read_csv('./dataset/simulazione/treni_solo_citta-.csv')\n",
    "\n",
    "\n",
    "# Creare un grafo non diretto\n",
    "G = nx.Graph()\n",
    "\n",
    "# Mappa per evitare sovrapposizioni di posizioni casuali\n",
    "posizioni_usate = {}\n",
    "\n",
    "# Aggiungi i nodi (città) al grafo con posizioni casuali non sovrapposte\n",
    "for idx, row in df_citta.iterrows():\n",
    "    # Genera posizione casuale non sovrapposta\n",
    "    while True:\n",
    "        x = random.uniform(0, 1)  # Coordinate x casuali tra 0 e 1\n",
    "        y = random.uniform(0, 1)  # Coordinate y casuali tra 0 e 1\n",
    "        pos = (x, y)\n",
    "        if pos not in posizioni_usate.values():\n",
    "            posizioni_usate[row['citta_uniche']] = pos\n",
    "            break\n",
    "    \n",
    "    G.add_node(row['citta_uniche'], pos=pos)\n",
    "\n",
    "# Aggiungi gli archi (connessioni tra città di partenza e arrivo) al grafo\n",
    "for idx, row in df_coppie.iterrows():\n",
    "    G.add_edge(row['stazPart'], row['stazArr'])\n",
    "\n",
    "G.remove_edges_from(nx.selfloop_edges(G))\n",
    "\n",
    "\n",
    "# Calcolo delle misurazioni di centralità e altre metriche\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "betweenness_centrality = nx.betweenness_centrality(G)\n",
    "eigenvector_centrality = nx.eigenvector_centrality(G, max_iter=1000)\n",
    "closeness_centrality = nx.closeness_centrality(G)\n",
    "clustering_coefficient = nx.clustering(G)\n",
    "density = nx.density(G)\n",
    "\n",
    "if nx.is_connected(G):\n",
    "    avg_path_length = nx.average_shortest_path_length(G)\n",
    "    diameter = nx.diameter(G)\n",
    "else:\n",
    "    avg_path_length = None\n",
    "    diameter = None\n",
    "\n",
    "connected_components = list(nx.connected_components(G))\n",
    "connectedness = len(connected_components)\n",
    "\n",
    "core_number = nx.core_number(G)\n",
    "assortativity = nx.degree_assortativity_coefficient(G)\n",
    "bridges = list(nx.bridges(G))\n",
    "\n",
    "# Stampa delle metriche\n",
    "print(\"Degree Centrality:\", degree_centrality)\n",
    "print(\"Betweenness Centrality:\", betweenness_centrality)\n",
    "print(\"Eigenvector Centrality:\", eigenvector_centrality)\n",
    "print(\"Closeness Centrality:\", closeness_centrality)\n",
    "print(\"Clustering Coefficient:\", clustering_coefficient)\n",
    "print(\"Density:\", density)\n",
    "print(\"Number of Connected Components:\", connectedness)\n",
    "print(\"Core Numbers:\", core_number)\n",
    "print(\"Assortativity:\", assortativity)\n",
    "print(\"Bridges:\", bridges)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calcola la degree centrality per ogni nodo\n",
    "degree_centrality = nx.degree_centrality(G)\n",
    "\n",
    "# Ordina i nodi per degree centrality e prendi i primi 10\n",
    "top_nodes_degree = sorted(degree_centrality.items(), key=lambda x: x[1], reverse=True)[:10]\n",
    "nodes_degree = [node for node, _ in top_nodes_degree]\n",
    "centrality_values_degree = [value for _, value in top_nodes_degree]\n",
    "\n",
    "# Plot a bar chart\n",
    "plt.figure(figsize=(12, 6))\n",
    "plt.bar(nodes_degree, centrality_values_degree, color='skyblue')\n",
    "plt.xlabel('Nodi')\n",
    "plt.ylabel('Degree Centrality')\n",
    "plt.title('Top 10 Degree Centrality dei Nodi')\n",
    "plt.xticks(rotation=45)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO CHECKLIST\n",
    "\n",
    "- capire bene i risultati\n",
    "- migliorare la mappa dell'italia, in particolar modo gli archi (confido in te super franci debuggatore)\n",
    "- aggiungere grafici (istogrammi)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
